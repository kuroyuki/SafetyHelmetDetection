{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset from https://www.kaggle.com/datasets/andrewmvd/hard-hat-detection and unpack it into ./data/hard-hat-detection folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['helmet','head','person']\n",
    "file_path = './data/hard-hat-detection/'\n",
    "ann_path = file_path + 'annotations/'\n",
    "img_path = file_path + 'images/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Prepare data: copy to train and val folders, convert annotations from xml to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segregate the dataset into train & validation (there are 5000 images)(train:4500, val:500)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "path_annotations = []\n",
    "for i in Path(ann_path).glob('*.xml'):\n",
    "    path_annotations.append(i)\n",
    "path_annotations = sorted(path_annotations) #contains path to 5000 annots\n",
    "\n",
    "path_images = []\n",
    "for i in Path(img_path).glob('*.png'):\n",
    "    path_images.append(i)\n",
    "path_images = sorted(path_images) #contains path to 5000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data : 90% Train, 10% Val\n",
    "path_train_annot = path_annotations[:4500]\n",
    "path_train_images = path_images[:4500]\n",
    "\n",
    "path_val_annot = path_annotations[4500:5000]\n",
    "path_val_images = path_images[4500:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dirs to segregate train & val images & annotations & also to save best trained model\n",
    "import os\n",
    "\n",
    "# Creating directories to put train & val data\n",
    "os.makedirs('./data/train/annotations',exist_ok = True)\n",
    "os.makedirs('./data/train/images', exist_ok = True)\n",
    "os.makedirs('./data/train/labels', exist_ok = True)\n",
    "os.makedirs('./data/val/annotations', exist_ok = True)\n",
    "os.makedirs('./data/val/images', exist_ok = True)\n",
    "os.makedirs('./data/val/labels', exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4500it [00:14, 311.14it/s]\n",
      "500it [00:01, 286.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# copying images & xml annotations from input to working folder\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, (path_annot, path_img) in tqdm(enumerate(zip(path_train_annot, path_train_images))):\n",
    "    shutil.copy(path_img, './data/train/images/' + path_img.parts[-1])\n",
    "    shutil.copy(path_annot, './data/train/annotations/' + path_annot.parts[-1])\n",
    "    \n",
    "for i, (path_annot, path_img) in tqdm(enumerate(zip(path_val_annot, path_val_images))):\n",
    "    shutil.copy(path_img, './data/val/images/' + path_img.parts[-1])\n",
    "    shutil.copy(path_annot, './data/val/annotations/' + path_annot.parts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.minidom import parse\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "def convert_annot(size , box):\n",
    "    x1 = int(box[0])\n",
    "    y1 = int(box[1])\n",
    "    x2 = int(box[2])\n",
    "    y2 = int(box[3])\n",
    "\n",
    "    dw = np.float32(1. / int(size[0]))\n",
    "    dh = np.float32(1. / int(size[1]))\n",
    "\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    x = x1 + (w / 2)\n",
    "    y = y1 + (h / 2)\n",
    "\n",
    "    x = x * dw\n",
    "    w = w * dw\n",
    "    y = y * dh\n",
    "    h = h * dh\n",
    "    return [x, y, w, h]\n",
    "\n",
    "def get_xml_data_and_save_as_txt(file_path, img_xml_file):\n",
    "    img_path = file_path + '/annotations/' + img_xml_file + '.xml'\n",
    "    #print(img_path)\n",
    "\n",
    "    dom = parse(img_path)\n",
    "    root = dom.documentElement\n",
    "    img_name = root.getElementsByTagName(\"filename\")[0].childNodes[0].data\n",
    "    img_size = root.getElementsByTagName(\"size\")[0]\n",
    "    objects = root.getElementsByTagName(\"object\")\n",
    "    img_w = img_size.getElementsByTagName(\"width\")[0].childNodes[0].data\n",
    "    img_h = img_size.getElementsByTagName(\"height\")[0].childNodes[0].data\n",
    "    img_c = img_size.getElementsByTagName(\"depth\")[0].childNodes[0].data\n",
    "   \n",
    "    img_box = []\n",
    "    for box in objects:\n",
    "        cls_name = box.getElementsByTagName(\"name\")[0].childNodes[0].data\n",
    "        x1 = int(box.getElementsByTagName(\"xmin\")[0].childNodes[0].data)\n",
    "        y1 = int(box.getElementsByTagName(\"ymin\")[0].childNodes[0].data)\n",
    "        x2 = int(box.getElementsByTagName(\"xmax\")[0].childNodes[0].data)\n",
    "        y2 = int(box.getElementsByTagName(\"ymax\")[0].childNodes[0].data)\n",
    "        \n",
    "        img_box.append([cls_name, x1, y1, x2, y2])\n",
    "  \n",
    "\n",
    "   \n",
    "    with open(file_path + '/labels/' + img_xml_file + '.txt' ,'a+') as file_path:\n",
    "        for box in img_box:\n",
    "\n",
    "            cls_num = classes.index(box[0])\n",
    "\n",
    "            new_box = convert_annot( [img_w, img_h], box[1:])\n",
    "\n",
    "            file_path.write(f\"{cls_num} {new_box[0]} {new_box[1]} {new_box[2]} {new_box[3]}\\n\")\n",
    "\n",
    "        file_path.flush()\n",
    "        file_path.close()\n",
    "\n",
    "def convert_annotations_to_labels(path):\n",
    "    for file in os.listdir(path+'/annotations'): \n",
    "        get_xml_data_and_save_as_txt(path, file[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_annotations_to_labels('./data/val')\n",
    "convert_annotations_to_labels('./data/train')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Setup Yolo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clone Yolo to ./yolov5 folder \n",
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wandb\" �� ���� ����७��� ��� ���譥�\n",
      "��������, �ᯮ��塞�� �ணࠬ��� ��� ������ 䠩���.\n"
     ]
    }
   ],
   "source": [
    "##have no idea what's this\n",
    "!wandb disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start training with 416x416 image size, 30 epochs, data config from ./hard_head.yaml, model config from yolov5s.yaml and save weights to yolov5s.pt\n",
    "!python ./yolov5/train.py --img 416 --batch 32 --epochs 30 --data ./hard_head.yaml --cfg ./yolov5/models/yolov5s.yaml --weights ./data/yolov5s.pt\n",
    "#file yolov5s.pt should be copied to our Telegram bot server where we can run detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'c:\\\\Users\\\\y.zhukov\\\\shared\\\\Politech\\\\SafetyHelmetDetection\\\\detect.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# detect images from ./data/val/images folder and use weight from yolov5s.pt and confidence 25%\n",
    "!python ./yolov5/detect.py --source ./data/val/images  --weights ./data/yolov5s.pt --conf 0.25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

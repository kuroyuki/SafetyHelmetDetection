{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset from https://www.kaggle.com/datasets/andrewmvd/hard-hat-detection and unpack it into ./data/hard-hat-detection folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['helmet','head','person']\n",
    "file_path = './data/hard-hat-detection/'\n",
    "ann_path = file_path + 'annotations/'\n",
    "img_path = file_path + 'images/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Prepare data: copy to train and val folders, convert annotations from xml to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segregate the dataset into train & validation (there are 5000 images)(train:4500, val:500)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "path_annotations = []\n",
    "for i in Path(ann_path).glob('*.xml'):\n",
    "    path_annotations.append(i)\n",
    "path_annotations = sorted(path_annotations) #contains path to 5000 annots\n",
    "\n",
    "path_images = []\n",
    "for i in Path(img_path).glob('*.png'):\n",
    "    path_images.append(i)\n",
    "path_images = sorted(path_images) #contains path to 5000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data : 90% Train, 10% Val\n",
    "path_train_annot = path_annotations[:4500]\n",
    "path_train_images = path_images[:4500]\n",
    "\n",
    "path_val_annot = path_annotations[4500:5000]\n",
    "path_val_images = path_images[4500:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making dirs to segregate train & val images & annotations & also to save best trained model\n",
    "import os\n",
    "\n",
    "# Creating directories to put train & val data\n",
    "os.makedirs('./data/train/annotations',exist_ok = True)\n",
    "os.makedirs('./data/train/images', exist_ok = True)\n",
    "os.makedirs('./data/train/labels', exist_ok = True)\n",
    "os.makedirs('./data/val/annotations', exist_ok = True)\n",
    "os.makedirs('./data/val/images', exist_ok = True)\n",
    "os.makedirs('./data/val/labels', exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4500it [00:22, 196.14it/s]\n",
      "500it [00:02, 187.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# copying images & xml annotations from input to working folder\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, (path_annot, path_img) in tqdm(enumerate(zip(path_train_annot, path_train_images))):\n",
    "    shutil.copy(path_img, './data/train/images/' + path_img.parts[-1])\n",
    "    shutil.copy(path_annot, './data/train/annotations/' + path_annot.parts[-1])\n",
    "    \n",
    "for i, (path_annot, path_img) in tqdm(enumerate(zip(path_val_annot, path_val_images))):\n",
    "    shutil.copy(path_img, './data/val/images/' + path_img.parts[-1])\n",
    "    shutil.copy(path_annot, './data/val/annotations/' + path_annot.parts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.minidom import parse\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "def convert_annot(size , box):\n",
    "    x1 = int(box[0])\n",
    "    y1 = int(box[1])\n",
    "    x2 = int(box[2])\n",
    "    y2 = int(box[3])\n",
    "\n",
    "    dw = np.float32(1. / int(size[0]))\n",
    "    dh = np.float32(1. / int(size[1]))\n",
    "\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    x = x1 + (w / 2)\n",
    "    y = y1 + (h / 2)\n",
    "\n",
    "    x = x * dw\n",
    "    w = w * dw\n",
    "    y = y * dh\n",
    "    h = h * dh\n",
    "    return [x, y, w, h]\n",
    "\n",
    "def get_xml_data_and_save_as_txt(file_path, img_xml_file):\n",
    "    img_path = file_path + '/annotations/' + img_xml_file + '.xml'\n",
    "    #print(img_path)\n",
    "\n",
    "    dom = parse(img_path)\n",
    "    root = dom.documentElement\n",
    "    img_name = root.getElementsByTagName(\"filename\")[0].childNodes[0].data\n",
    "    img_size = root.getElementsByTagName(\"size\")[0]\n",
    "    objects = root.getElementsByTagName(\"object\")\n",
    "    img_w = img_size.getElementsByTagName(\"width\")[0].childNodes[0].data\n",
    "    img_h = img_size.getElementsByTagName(\"height\")[0].childNodes[0].data\n",
    "    img_c = img_size.getElementsByTagName(\"depth\")[0].childNodes[0].data\n",
    "   \n",
    "    img_box = []\n",
    "    for box in objects:\n",
    "        cls_name = box.getElementsByTagName(\"name\")[0].childNodes[0].data\n",
    "        x1 = int(box.getElementsByTagName(\"xmin\")[0].childNodes[0].data)\n",
    "        y1 = int(box.getElementsByTagName(\"ymin\")[0].childNodes[0].data)\n",
    "        x2 = int(box.getElementsByTagName(\"xmax\")[0].childNodes[0].data)\n",
    "        y2 = int(box.getElementsByTagName(\"ymax\")[0].childNodes[0].data)\n",
    "        \n",
    "        img_box.append([cls_name, x1, y1, x2, y2])\n",
    "  \n",
    "\n",
    "   \n",
    "    with open(file_path + '/labels/' + img_xml_file + '.txt' ,'a+') as file_path:\n",
    "        for box in img_box:\n",
    "\n",
    "            cls_num = classes.index(box[0])\n",
    "\n",
    "            new_box = convert_annot( [img_w, img_h], box[1:])\n",
    "\n",
    "            file_path.write(f\"{cls_num} {new_box[0]} {new_box[1]} {new_box[2]} {new_box[3]}\\n\")\n",
    "\n",
    "        file_path.flush()\n",
    "        file_path.close()\n",
    "\n",
    "def convert_annotations_to_labels(path):\n",
    "    for file in os.listdir(path+'/annotations'): \n",
    "        get_xml_data_and_save_as_txt(path, file[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_annotations_to_labels('./data/val')\n",
    "convert_annotations_to_labels('./data/train')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Setup Yolo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "dict_file = {'train':'./data/train/images' ,\n",
    "            'val': './data/val/images',\n",
    "            'nc' : '3',\n",
    "            'names' : ['helmet','head','person']}\n",
    "\n",
    "#save our config to data folder as yaml file\n",
    "with open('./hard_head.yaml', 'w+') as file:\n",
    "    documents = yaml.dump(dict_file, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wandb\" �� ���� ����७��� ��� ���譥�\n",
      "��������, �ᯮ��塞�� �ணࠬ��� ��� ������ 䠩���.\n"
     ]
    }
   ],
   "source": [
    "##have no idea what's this\n",
    "!wandb disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\y.zhukov\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\git\\__init__.py\", line 89, in <module>\n",
      "    refresh()\n",
      "  File \"C:\\Users\\y.zhukov\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\git\\__init__.py\", line 76, in refresh\n",
      "    if not Git.refresh(path=path):\n",
      "  File \"C:\\Users\\y.zhukov\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\git\\cmd.py\", line 392, in refresh\n",
      "    raise ImportError(err)\n",
      "ImportError: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\y.zhukov\\shared\\Politech\\SafetyHelmetDetection\\yolov5\\train.py\", line 67, in <module>\n",
      "    GIT_INFO = check_git_info()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\contextlib.py\", line 79, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"c:\\Users\\y.zhukov\\shared\\Politech\\SafetyHelmetDetection\\yolov5\\utils\\general.py\", line 358, in check_git_info\n",
      "    import git\n",
      "  File \"C:\\Users\\y.zhukov\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\git\\__init__.py\", line 91, in <module>\n",
      "    raise ImportError(\"Failed to initialize: {0}\".format(exc)) from exc\n",
      "ImportError: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#start training with 416x416 image size, 30 epochs, data config from ./hard_head.yaml, model config from yolov5s.yaml and save weights to yolov5s.pt\n",
    "!python ./yolov5/train.py --img 416 --batch 32 --epochs 30 --data ./hard_head.yaml --cfg ./yolov5/models/yolov5s.yaml --weights yolov5s.pt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect images from ./data/val/images folder and use weight from yolov5s.pt and confidence 25%\n",
    "!python detect.py --source ./data/val/images  --weights yolov5s.pt --conf 0.25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
